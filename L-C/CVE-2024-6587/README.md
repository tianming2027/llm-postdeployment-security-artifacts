# CVE-2024-6587 (LiteLLM Proxy) — SSRF via `api_base` → Upstream Key Exfiltration → Response Hijacking (Lab Case)

## Overview

This lab case documents a controlled experiment for **CVE-2024-6587** in **LiteLLM** (Proxy / Gateway). Public advisories describe a **Server-Side Request Forgery (SSRF)** where a client can supply a user-controlled **`api_base`** in requests to **`POST /chat/completions`**. In affected versions, the proxy may forward the request to that attacker-specified domain **while attaching the proxy’s configured upstream API key** (e.g., OpenAI key), enabling **credential exfiltration** and **response manipulation**.

In this experiment, we demonstrate two impacts:

1) **Credential exfiltration (lab-only):** the attacker-controlled upstream receives the forwarded request and captures the `Authorization` header.  
2) **Response hijacking:** the attacker-controlled upstream returns a forged **streaming (SSE) response**, fully replacing the model’s real output.

- **CVE:** CVE-2024-6587  
- **Product:** LiteLLM (Proxy / AI Gateway)  
- **Affected versions:** reported in advisories as vulnerable in **1.38.10** and affected across a broader range (see References).  
- **Fix:** advisories indicate a fix around **1.44.8 / 1.44.9** (upgrade to the latest stable release).  
- **Impact in this case:** **user-controlled upstream routing → key leak → response hijack**

---

## Critical Clarification (This is not prompt injection)

This is **not** “bad content poisoning” or “prompt injection”.

The core chain is:

1. The proxy accepts a user-controlled **`api_base`** (upstream base URL) as part of a normal chat completion request.  
2. The proxy forwards the request to that destination (SSRF / arbitrary upstream routing).  
3. The forwarded request includes the proxy’s **configured upstream credentials** (e.g., OpenAI API key), which can be captured by the attacker.  
4. The attacker can return arbitrary content (including streaming SSE), causing **full response hijacking**.

---

## Contents of This Case Folder

```text
CVE-2024-6587/
  README.md
  attack_qwen_server.py         # Attacker-controlled "fake upstream": prints Authorization + returns forged SSE stream
  user_simulator.py             # Client simulator: calls LiteLLM proxy and prints streaming output (evidence helper)
  assets/
    after_hijack.png            # Hijacked answer evidence
```

## Lab Topology (What We Ran)

- **LiteLLM Proxy (victim)** running locally (example: `http://127.0.0.1:4000`), configured with a **lab-only upstream API key** (do NOT use production credentials).
- **Attacker server (fake upstream)** running locally (example: `http://127.0.0.1:9000`), exposing:
  - `POST /chat/completions` to capture the forwarded request and return a forged SSE stream.
- **Public tunnel (ngrok)** exposing the attacker server as `https://<TUNNEL_DOMAIN>`.
- **Client (curl or `user_simulator.py`)** sending a normal chat request to the proxy while injecting `api_base = https://<TUNNEL_DOMAIN>`.

------

## What the Scripts Do (Evidence Helpers)

### `attack_qwen_server.py` (Attacker / Fake Upstream)

- Reads `Authorization` from incoming requests and prints it (credential leak proof).
- Returns a **streaming SSE** response with attacker-controlled content, demonstrating response hijacking.

### `user_simulator.py` (User / Client View)

- Sends a streaming request to the LiteLLM proxy.
- Includes `api_base` pointing to the attacker-controlled tunnel (injection point).
- Parses `data: {...}` SSE chunks and prints `delta.content` so you can screenshot the result.

------

## Vulnerability Mechanism 

Public sources describe CVE-2024-6587 as:

- A **SSRF / arbitrary upstream routing** issue where a user can supply `api_base` in `POST /chat/completions`, causing LiteLLM to send the request to the specified domain.
- The forwarded request includes the **OpenAI API key** (or equivalent configured upstream credential), enabling key exfiltration and misuse.
- The attacker-controlled upstream can also return **forged responses** (including streaming), fully controlling what the end-user sees.

------

## Experiment Flow 

### Phase A — Establish a Baseline (Clean Behavior)

1. Start LiteLLM proxy in a lab environment with a **fake / lab-only** upstream API key configured.
2. Send a normal chat completion request *without* overriding upstream routing.

### Phase B — Prepare Attacker Infrastructure (Fake Upstream + Tunnel)

1. Start `attack_qwen_server.py` on a local port (e.g., 9000).
2. Start ngrok to expose that port and obtain `https://<TUNNEL_DOMAIN>`.

### Phase C — Trigger the SSRF / Routing Override

1. Send a chat completion request to the LiteLLM proxy that includes:
   - `stream: true` (for visible streaming evidence), and
   - `api_base: "https://<TUNNEL_DOMAIN>"` (attacker-controlled upstream).
2. Observe:
   - The attacker server prints the incoming `Authorization` header (credential leak evidence).
   - The client receives the attacker’s forged streaming response instead of the real model output (hijack evidence).

### Phase D — Evidence Collection

Capture:

- Client-side output: `assets/after_hijack.png`

------

## Expected Outcome

- **Before hijack:** The user receives the real model output (or expected proxy behavior).
- **After hijack:**
  - The attacker-controlled upstream receives a forwarded request containing `Authorization: Bearer <UPSTREAM_KEY>` (confidentiality breach).
  - The user sees a forged streaming response controlled by the attacker (integrity breach of responses).

------

## Notes / Troubleshooting

- If the attacker server never receives requests:
  - The proxy may be patched (upgrade applied), or
  - Egress rules / firewalling may block outbound access from the proxy to the tunnel domain.
- If the client doesn’t show hijacked text:
  - Confirm the client is reading SSE streaming output and the attacker server returns `text/event-stream`.
- If you’re validating a fix:
  - Ensure the proxy **ignores, rejects, or strictly allowlists** any user-supplied upstream base URL (`api_base`).

------

## Public References

- NVD — CVE-2024-6587
   [https://nvd.nist.gov/vuln/detail/CVE-2024-6587](https://nvd.nist.gov/vuln/detail/CVE-2024-6587?utm_source=chatgpt.com)
- GitLab Advisory Database — CVE-2024-6587 (LiteLLM)
   [https://advisories.gitlab.com/pkg/pypi/litellm/CVE-2024-6587/](https://advisories.gitlab.com/pkg/pypi/litellm/CVE-2024-6587/?utm_source=chatgpt.com)
- CVE.org Record — CVE-2024-6587 (status + references/commit)
   [https://www.cve.org/CVERecord?id=CVE-2024-6587](https://www.cve.org/CVERecord?id=CVE-2024-6587&utm_source=chatgpt.com)
- Snyk — SSRF in litellm (summary + impact)
   [https://security.snyk.io/vuln/SNYK-PYTHON-LITELLM-7981517](https://security.snyk.io/vuln/SNYK-PYTHON-LITELLM-7981517?utm_source=chatgpt.com)