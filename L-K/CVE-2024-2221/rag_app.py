import sys
import ollama
from qdrant_client import QdrantClient, models
from sentence_transformers import SentenceTransformer

# --- 配置 ---
COLLECTION_NAME = "knowledge_base"
QDRANT_URL = "http://localhost:6333"

# --- 初始化客户端和模型 ---
qdrant_client = QdrantClient(url=QDRANT_URL)
embedding_model = SentenceTransformer("all-MiniLM-L6-v2") # 用于文本向量化

def setup_collection():
    """确保 Qdrant 集合存在"""
    try:
        qdrant_client.recreate_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=models.VectorParams(
                size=embedding_model.get_sentence_embedding_dimension(),
                distance=models.Distance.COSINE,
            ),
        )
        print(f"集合 '{COLLECTION_NAME}' 已创建/重置。")
    except Exception as e:
        print(f"创建集合失败: {e}")

def upsert_knowledge(text: str, doc_id: int):
    """将知识存入 Qdrant"""
    vector = embedding_model.encode(text).tolist()
    qdrant_client.upsert(
        collection_name=COLLECTION_NAME,
        points=[models.PointStruct(id=doc_id, vector=vector, payload={"text": text})],
        wait=True,
    )
    print(f"知识已添加: (ID: {doc_id}) '{text}'")

def ask_question(query: str):
    """向 RAG 系统提问"""
    query_vector = embedding_model.encode(query).tolist()

    search_results = qdrant_client.search(
        collection_name=COLLECTION_NAME,
        query_vector=query_vector,
        limit=1,
    )

    if not search_results:
        print("知识库中未找到相关信息。")
        return

    context = search_results[0].payload["text"]
    prompt = f"""
    Use the following context to answer the question.
    Context: "{context}"
    Question: {query}
    """
    
    print(f"\n--- 向大模型提问 ---\n上下文: {context}\n问题: {query}\n---")

    # 调用本地的 tinyllama 模型
    response = ollama.chat(
        model='tinyllama', # <--- 这里是唯一的修改点
        messages=[{'role': 'user', 'content': prompt}],
    )
    
    print("\n>>> 大模型的回答:")
    print(response['message']['content'])

def print_vector(text: str):
    """辅助函数，打印文本的向量"""
    vector = embedding_model.encode(text).tolist()
    print(vector)


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("用法: python rag_app.py [setup|add|ask|get_vector] [参数]")
        sys.exit(1)

    command = sys.argv[1]

    if command == "setup":
        setup_collection()
    elif command == "add":
        upsert_knowledge("The current CEO of Microsoft is Satya Nadella.", doc_id=1)
    elif command == "ask":
        question = " ".join(sys.argv[2:])
        ask_question(question)
    elif command == "get_vector":
        text_to_vectorize = " ".join(sys.argv[2:])
        print_vector(text_to_vectorize)
    else:
        print("未知命令。")
